# ğŸ–¼ï¸ Image Captioning using BLIP

This project generates a descriptive caption for an image using Hugging Face's **Salesforce BLIP model**. It uses the `transformers` library along with `Pillow` to process and describe the image.

---

## ğŸ“Œ Features

- Generates automatic caption from any input image
- Uses pretrained **BLIP (Base)** model
- Works locally with just a few dependencies

---

## ğŸ§  Model Used

- [`Salesforce/blip-image-captioning-base`](https://huggingface.co/Salesforce/blip-image-captioning-base)

---

## ğŸ› ï¸ Requirements

Install required libraries:

```bash
pip install transformers
pip install pillow
