# 🖼️ Image Captioning using BLIP

This project generates a descriptive caption for an image using Hugging Face's **Salesforce BLIP model**. It uses the `transformers` library along with `Pillow` to process and describe the image.

---

## 📌 Features

- Generates automatic caption from any input image
- Uses pretrained **BLIP (Base)** model
- Works locally with just a few dependencies

---

## 🧠 Model Used

- [`Salesforce/blip-image-captioning-base`](https://huggingface.co/Salesforce/blip-image-captioning-base)

---

## 🛠️ Requirements

Install required libraries:

```bash
pip install transformers
pip install pillow
